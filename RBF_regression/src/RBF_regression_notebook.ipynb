{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF Regression on Boston hosting Dataset\n",
    "### Charis Filis\n",
    "### Academic-id : 9449 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add needed dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Import  tensorflow.keras basic NNet modules for the RBF output layer\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras import initializers\n",
    "# Import tensorflow.keras backend for any tensor operations\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "# Images, plots, display, and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# import addons for RSqure metric\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "# Import pairwise metric \n",
    "from sklearn.metrics import pairwise\n",
    "# Import KMeans algorithm in case the custom one does not work properly\n",
    "from sklearn.cluster import KMeans\n",
    "# Import numpy for array and numeric operations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.1770e-02 8.2500e+01 2.0300e+00 0.0000e+00 4.1500e-01 7.6100e+00\n",
      " 1.5700e+01 6.2700e+00 2.0000e+00 3.4800e+02 1.4700e+01 3.9538e+02\n",
      " 3.1100e+00] 42.3\n",
      "Number of original training examples: 379\n",
      "Number of original test examples: 127\n",
      "Training data shape: (379, 13)\n",
      "Training y train shape (379,)\n",
      "Testing data shape: (127, 13)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = boston_housing.load_data(test_split=0.25)\n",
    "\n",
    "\n",
    "#Convert to float32\n",
    "x_train, x_test = np.array(x_train, dtype=np.float32), np.array(x_test, dtype=np.float32)\n",
    "print(x_train[1], y_train[1])\n",
    "# get per-feature statistics (mean,standard deviation ) from the training set in order to make normalization\n",
    "train_mean = np.mean(x_train, axis=0)\n",
    "train_std = np.std(x_train,axis=0)\n",
    "x_train = (x_train-train_mean)/train_std\n",
    "print(\"Number of original training examples:\", len(x_train))\n",
    "print(\"Number of original test examples:\", len(x_test))\n",
    "print(\"Training data shape:\",x_train.shape)\n",
    "print(\"Training y train shape\", y_train.shape)\n",
    "print(\"Testing data shape:\",x_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R squared metric custom made "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(test_val, pred_val):\n",
    "    SS_res = K.sum(K.square(test_val-pred_val))\n",
    "    SS_tot = K.sum(K.square(test_val-K.mean(test_val)))\n",
    "    return (1 - SS_res/(SS_tot+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1 compute centers and sigma and Number of Kernels = 0.1 Ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.340571, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "# Variance of each kernel\n",
    "from cmath import sqrt\n",
    "# num of kernels in hidden layer = number of inputs = number of nodes of  RBF layer\n",
    "n_centers = int(0.1*x_train.shape[0])\n",
    "\n",
    "def computeSigma(n_centers):\n",
    "        km = KMeans(n_clusters=n_centers, init='random', verbose=0).fit(x_train)\n",
    "        centers = km.cluster_centers_\n",
    "        dists = pdist(centers, metric='euclidean')\n",
    "        d_max = np.amax(dists)\n",
    "        sigma = d_max / tf.math.sqrt(2*float(centers.shape[0])) \n",
    "        return sigma\n",
    "   \n",
    "sigma = computeSigma(n_centers)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (574062755.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [1], line 19\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# custom Kmeans algorithm that returns cluster centers and standart deviation of each cluster\n",
    "\"\"\"\n",
    "1D-Input Clustering\n",
    "A := numpy array MX1 - Data\n",
    "k := integer - Number of Clusters\n",
    "\"\"\"\n",
    "def kmeans_custom(A,k):\n",
    "    \n",
    "    # get Number of Features\n",
    "    numFeatures = A.shape[1]\n",
    "    # random initialization of centroids\n",
    "    clusters_c = np.random.choice(np.squeeze(A),size=k)\n",
    "    # kmeans is a greedy algorithm so we need a converge flag to stop him from running infinately\n",
    "    converge_flag = False\n",
    "    # initialize standart deviation buffer\n",
    "    stds_c = np.zeros(k)\n",
    "    \n",
    "    while not converge_flag:\n",
    "        \"\"\"\n",
    "            Compute distances of each cluster center to each point \n",
    "            of the dataset\n",
    "        \"\"\"\n",
    "        distances = np.squeeze(np.abs(A[:,np.newaxis]- clusters_c[np.newaxis, :]))\n",
    "        # Find the cluster that is closest to each point\n",
    "        closer_cluster = np.argmin(distances,axis=1)\n",
    "        \n",
    "        for iter in range(k):\n",
    "            clusterSet = A[closer_cluster == iter]\n",
    "            if len(clusterSet) >  0:\n",
    "                clusters_c\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import Initializer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "class InitCentersKMeans(Initializer):\n",
    "    \"\"\" Initializer for initialization of centers of RBF network\n",
    "        by clustering the given data set.\n",
    "    # Arguments\n",
    "        X: matrix, dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, max_iter=100):\n",
    "        self.X = X\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        assert shape[1] == self.X.shape[1]\n",
    "\n",
    "        n_centers = shape[0]\n",
    "        km = KMeans(n_clusters=n_centers, max_iter=self.max_iter, verbose=0)\n",
    "        km.fit(self.X)\n",
    "        return km.cluster_centers_\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create RBF layer or RBF kernel would be described"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self,units,initializer,sigmaInit,**kwards):\n",
    "        super(RBFLayer,self).__init__(**kwards)\n",
    "        self.units = units\n",
    "        self.sigmaInit = sigmaInit\n",
    "        self.initializer= initializer\n",
    "    def build(self, input_shape):\n",
    "        # I initialize the weights of rbf layer with kmeans \n",
    "        self.W = self.add_weight(name='W',\n",
    "                                 shape=(int(input_shape[1],), self.units),\n",
    "                                 initializer=self.initializer,\n",
    "                                 trainable=True)\n",
    "        self.b  = self.add_weight(shape=(self.units,),\n",
    "                            initializer=self.initializer,\n",
    "                            trainable=True)\n",
    "\n",
    "        super(RBFLayer,self).build(input_shape)\n",
    "    \n",
    "    # radial basis function\n",
    "    def call(self, inputs):\n",
    "        diff = K.expand_dims(inputs) - self.W\n",
    "        # take L2 norm for the exponent of the radial basis function\n",
    "        l2 = K.sum(K.pow(diff,2), axis=1)\n",
    "        res = K.exp((-1 * l2)/(2*(self.sigmaInit**2)))     \n",
    "        return tf.matmul(res.transpose(), self.W) + self.b\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape, self.units)\n",
    "                                 \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 1st model builder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(models):\n",
    "    model_out = models.Sequential()\n",
    "    # RBF layer\n",
    "    model_out.add(RBFLayer(units = (int)(0.1*x_train.shape[0]),initializer=InitCentersKMeans(x_train),sigmaInit=sigma))\n",
    "    # Output Layer\n",
    "    rbf_out_shape = RBFLayer(units = (int)(0.1*x_train.shape[0]),initializer=InitCentersKMeans(x_train),sigmaInit=sigma).compute_output_shape(input_shape=((int)(x_train.shape[1],)))\n",
    "    model_out.add(layers.Dense(128,activation='relu',input_shape=rbf_out_shape,\n",
    "                               kernel_initializer=initializers.RandomNormal(mean = 0,stddev=0.4)))\n",
    "    \n",
    "    # Make the linear tranformation layer on the output layer\n",
    "    model_out.add(layers.Dense(1,activation='relu',\n",
    "                  kernel_initializer= initializers.RandomNormal(mean = 0,stddev=0.4)))\n",
    "    model_out.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.001,momentum=0),\n",
    "                      loss= [RootMeanSquaredError, tfa.metrics.RSquare])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\harry\\Documents\\Computational_Intelligence_Thmmy\\Assignment\\RBF_regression\\src\\RBF_regression_notebook.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/harry/Documents/Computational_Intelligence_Thmmy/Assignment/RBF_regression/src/RBF_regression_notebook.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_out \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mSequential()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/harry/Documents/Computational_Intelligence_Thmmy/Assignment/RBF_regression/src/RBF_regression_notebook.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_out\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39mDense(\u001b[39m0.1\u001b[39m\u001b[39m*\u001b[39mx_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], input_shape\u001b[39m=\u001b[39m(x_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],)))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/harry/Documents/Computational_Intelligence_Thmmy/Assignment/RBF_regression/src/RBF_regression_notebook.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_out\u001b[39m.\u001b[39madd(RBFLayer(units \u001b[39m=\u001b[39m (\u001b[39mint\u001b[39m)(\u001b[39m0.1\u001b[39m\u001b[39m*\u001b[39mx_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]),initializer\u001b[39m=\u001b[39mInitCentersKMeans(shape\u001b[39m=\u001b[39;49m(x_train\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m],)),sigmaInit\u001b[39m=\u001b[39msigma))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/harry/Documents/Computational_Intelligence_Thmmy/Assignment/RBF_regression/src/RBF_regression_notebook.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Output Layer\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/harry/Documents/Computational_Intelligence_Thmmy/Assignment/RBF_regression/src/RBF_regression_notebook.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m rbf_out_shape \u001b[39m=\u001b[39m RBFLayer(units \u001b[39m=\u001b[39m (\u001b[39mint\u001b[39m)(\u001b[39m0.1\u001b[39m\u001b[39m*\u001b[39mx_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]),initializer\u001b[39m=\u001b[39mInitCentersKMeans(shape\u001b[39m=\u001b[39m(x_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],)),sigmaInit\u001b[39m=\u001b[39msigma)\u001b[39m.\u001b[39mcompute_output_shape(input_shape\u001b[39m=\u001b[39m((\u001b[39mint\u001b[39m)(x_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],)))\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'shape'"
     ]
    }
   ],
   "source": [
    "model_out = models.Sequential()\n",
    "model_out.add(layers.Dense(0.1*x_train.shape[0], input_shape=(x_train.shape[0],)))\n",
    "model_out.add(RBFLayer(units = (int)(0.1*x_train.shape[0]),initializer=InitCentersKMeans(shape=(x_train.shape[0],)),sigmaInit=sigma))\n",
    "# Output Layer\n",
    "rbf_out_shape = RBFLayer(units = (int)(0.1*x_train.shape[0]),initializer=InitCentersKMeans(shape=(x_train.shape[0],)),sigmaInit=sigma).compute_output_shape(input_shape=((int)(x_train.shape[1],)))\n",
    "model_out.add(layers.Dense(128,activation='relu',input_shape=rbf_out_shape,\n",
    "                            kernel_initializer=initializers.RandomNormal(mean = 0,stddev=0.4)))\n",
    "\n",
    "# Make the linear tranformation layer on the output layer\n",
    "model_out.add(layers.Dense(1,activation='relu',\n",
    "                kernel_initializer= initializers.RandomNormal(mean = 0,stddev=0.4)))\n",
    "model_out.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "                    loss = tf.keras.losses.MeanSquaredError(),\n",
    "                    metrics = [tf.keras.metrics.RootMeanSquaredError(), R2])\n",
    "history_1 = model_out.fit(x_train,y_train,epochs=100,batch_size=128,validation_split=0.2,verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconsideration\n",
    "At this point i realize that keras models are not working well with custom made layers such as the one RBF I made. After research and communication with a professor,\n",
    "I came to an understanding that RBF layer is just a kernel that could be applied to data and the we can instantly proceed adn push that data to the output layer.\n",
    "So because I have no time for debugging im using sklearn to create a custom rbf kernel from pairwise lib and I apply this to a specific number of data inputs in order to have the correct. Last but not least I want to point out that there are implementation of creating rbf Layers that work with keras and I found some but they are not quite effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "# apply kmeans to find initial centers\n",
    "km = KMeans(n_clusters=n_centers, init='random', verbose=0).fit(x_train)\n",
    "centers = km.cluster_centers_\n",
    "# typecast 1/2sigma to float vector in order to be applied to kernel\n",
    "x_rbf_out = rbf_kernel(x_train,Y =centers, gamma = np.float32( 1/(2*sigma)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output layer model builder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_layer_builder():\n",
    "    model_out = models.Sequential()\n",
    "    # RBF layer kernel applied to data as transformation\n",
    "    # Output Layer\n",
    "    model_out.add(layers.Dense(128, activation='relu', input_shape=(x_rbf_out.shape[1],),\n",
    "                         kernel_initializer=initializers.RandomNormal(mean = 0,stddev=0.4)))\n",
    "    \n",
    "    # Make the linear tranformation layer on the output layer\n",
    "    model_out.add(layers.Dense(1,activation='relu',\n",
    "                  kernel_initializer= initializers.RandomNormal(mean = 0,stddev=0.4)))\n",
    "    model_out.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "                    loss = tf.keras.losses.MeanSquaredError(),\n",
    "                    metrics = [tf.keras.metrics.RootMeanSquaredError(), R2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\harry\\Documents\\Computational_Intelligence_Thmmy\\Assignment\\RBF_regression\\src\\RBF_regression_notebook.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/harry/Documents/Computational_Intelligence_Thmmy/Assignment/RBF_regression/src/RBF_regression_notebook.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_1 \u001b[39m=\u001b[39m output_layer_builder()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/harry/Documents/Computational_Intelligence_Thmmy/Assignment/RBF_regression/src/RBF_regression_notebook.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m history_1 \u001b[39m=\u001b[39m model_1\u001b[39m.\u001b[39;49mfit(x_rbf_out,y_train,epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,batch_size\u001b[39m=\u001b[39m\u001b[39m48\u001b[39m,validation_split\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/harry/Documents/Computational_Intelligence_Thmmy/Assignment/RBF_regression/src/RBF_regression_notebook.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Plot RSQ\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/harry/Documents/Computational_Intelligence_Thmmy/Assignment/RBF_regression/src/RBF_regression_notebook.ipynb#X40sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "\n",
    "model_1 = output_layer_builder()\n",
    "history_1 = model_1.fit(x_rbf_out,y_train,epochs=100,batch_size=48,validation_split=0.2,verbose=1)\n",
    "\n",
    "# Plot RSQ\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['RSquare'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot RMSE\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['root_mean_squared_error'],label='train')\n",
    "plt.plot(history.history['val_root_mean_squared_error'],label='test')\n",
    "plt.legend()\n",
    "plt.title('RMSE on training and validation sets')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40fcdd4a0e98f93efe88366db2abec70317af01b338acd99e2ac692059567cf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
